---
layout: page
title: 机器学习:分类模型的评价指标
categories: [机器学习]
tags: [机器学习]
keywords: 
description: 摘要描述
mathjax: true
---

## 常识中的指标

### **错误率**(err)

分类错误的样本数占样本总数的比例。
$$
err = 1-acc
$$
### **精度**(acc)

分类正确的样本数占样本总数的比例，用于衡量分类器正确的识别新样本的能力。
$$
acc = (TP+TN)/(TP+TN+FP+FN)
$$

## 常见指标

### **查准率**(Precision)

衡量分类器不将负样本错误地识别为正样本的能力。
$$
P = TP / (TP+FP)
$$
### **查全率、召回率**(Recall)

衡量分类器查找所有正样本的能力。
$$
R = TP / (TP + FN)
$$
对于多类别，模型的精度是指准确率的微平均(micro-avg)，模型的查准率是指准确率的宏平均(macro-avg)。若样本分布为自然分布，那么微平均衡量的是模型当下的表现；而宏平均衡量的时模型未来的表现（考虑到自然分布可能会发生变化），属于风险预估。宏平均指标相对微平均指标而言受小类别的影响更大。[【ref】](https://blog.csdn.net/xiaqian0917/article/details/53445071) 

但当正负样本不平衡时，准确率或召回率这一评价指标将会有很大缺陷。比如训练一个用于识别癌症的模型，混淆矩阵为：

|        | normal | cancer |
| :----: | -----: | -----: |
| normal |     98 |      0 |
| cancer |      1 |      1 |

那么：
$$
P_{cancer} = 1/(1+0) = 1, \\
R_{cancer} = 1/(1+1) = 0.5
$$
### **F值**

故，当正负样本均衡时既不能单独看查准率也不能单独地看查全率，由此引入F值：
$$
F_{\alpha} = \frac{(\alpha^2 +1)PR}{\alpha^2 P + R}, \alpha > 0.
$$
$\alpha$ 用于[衡量查全率对查准率的相对重要性](http://www.dcs.gla.ac.uk/Keith/Preface.html)，$\alpha > 1$ 更看重查全率，反之更看重查准率，标准的$F_1$意味查全查准重要性等同。故此时可用$F_1$这一评价指标来评价该模型对癌症这一类别的识别能力：
$$
F1_{cancer} = 2 * (1 * 0.5)/(1+0.5) = 0.667
$$

## 进阶指标

### ROC, P-R

P-R曲线、ROC曲线定义如下：

![PR_ROC](https://bkseastone.github.io/images/PR_ROC.jpg)

### AP, mAP

P-R曲线下的面积为AP，即在不同召回率下准确率的均值，而mAP即为各类AP的平均。

### AUC

ROC曲线下的面积为AUC（1-AUC也可作loss函数），计算方法如下：

![AUC](https://bkseastone.github.io/images/AUC.jpg)

可如此解释：对于随机给定的一个正样本和一个负样本，分类器输出正样本为正的那个概率值比输出负样本为正的那个概率值要大的可能性；或是意为分类器对于随机给定的正样本的打分高于随机给定的负样本的概率，即正例得分大于负例得分的概率。