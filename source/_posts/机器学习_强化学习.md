---
layout: page
title: 机器学习:强化学习
categories: [机器学习]
tags: [ml, dl]
keywords: 
description: 摘要描述
mathjax: true
---

# 基础

## Q-learning

> 关键：将（采取动作后的新状态下的最大Q值 + 采取该行动后得到的奖励）作为原状态下对应行动的Q值的目标值。

| notation  | 含义                                                    |
| :-------: | :------------------------------------------------------ |
|     s     | 当前状态                                                |
|    s_     | 采取动作后的新状态                                      |
|     a     | 动作                                                    |
|    Q表    | 在各个状态s下采取各个动作a得到的Q值组成的表             |
| Q(s0, a0) | 在状态s0下采取动作a0得到的Q值                           |
|   Q(s0)   | 在状态s0下采取某个动作a所能得到的最大Q值                |
|     r     | 奖励，通过设置不同状态对应不同奖励从而求得任务所需的Q表 |

Q表更新（学习）规则：
$$
Q_{s_0, a_0} = Q_{s_0, a_0} + \alpha [(r_{s_1} + \gamma Q_{s_1}) - Q_{s_0, a_0}]
$$
其中 $\gamma$ 为未来奖励的衰减率，$\alpha$ 为学习率，对其做递归展开得（设 $\alpha = 1$ ）：
$$
\begin{align*}
Q_{s_0, a_0} &= Q_{s_0}  \\
&= r_{s_1} + \gamma Q_{s_1} \\
&= r_{s_1} + \gamma (r_{s_2} + \gamma Q_{s_2}) \\
&= r_{s_1} + \gamma r_{s_2} + \gamma^2 r_{s_3} + \dotso
\end{align*}
$$

故 $\gamma$ 越大，对未来考虑越多。

详见[demo(treasure_on_right)](https://github.com/bkseastone/Amadeus/blob/master/RL/Q_learning/treasure_on_right.py) 。

## Deep Q-learning

> 用神经网络来实现Q表的功能，解决状态取值为连续区间的问题（Q表允许的状态取值为离散值）。

![demo_DQN](https://img.vim-cn.com/f5/f44f6609332cfae2740526d30c841d8069475f.png)

训练细节：

* batchsize = 32，于 200 个 batch 后做 target_replace_op，以保证收敛
* 每 5 步做一次学习，大前提是已做了至少 200 步的仿真（记忆库最大容量设为 2000，每个 batch 是从记忆库中随机挑选的）

详见[demo(DQN/run)](https://github.com/bkseastone/Amadeus/blob/master/RL/Q_learning/run.py) 。

## Policy Gradient

> DQN 状态可以达到无限，但因输出的是已设定的各个动作的Q值（概率），故动作数量依然是有限的（有几个输出神经元便是所能采取的动作数量）；通过直接输出动作的值而不是某个动作的概率的方法，可使得输出动作达到无限，这种方法称为 Policy Gradient 。

![demo_policy-gradient](https://img.vim-cn.com/89/07d84c0c31ad34e5af7d388d1186dbb9aded5e.png)

因为没有误差，只用奖励做参数更新，故只能回合更新：
$$
vt[t] = vt[t] * 0.99 + ep_rs[t], \quad (t 为倒序).
$$
详见[demo(RL_brain/demo)](https://github.com/bkseastone/Amadeus/blob/master/RL/PolicyGradients/demo.py) 。

# 在目标检测中的应用

## RPN

### Deep Reinforcement Learning of Region Proposal Networks for Object Detection

详见 [pdf](https://github.com/bkseastone/archived/blob/master/Deep%20Reinforcement%20Learning%20of%20Region%20Proposal%20Networks%20for%20Object%20Detection.pdf) ，[source](https://github.com/aleksispi/drl-rpn-tf) 。